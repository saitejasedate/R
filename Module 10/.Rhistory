q()
q()
sd(c(5,8,12))
which.min(c(4,1,6))
demo()
q()
q()
install.packages("ggplot2")
library(ggplot2)
install.packages("maps")
library(maps)
install.packages("ggmap")
state = read.csv("statedata.csv")
statesMap = map_data("state")
table(statesMap$group)
length(table(statesMap$group))
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
polling = read.csv("PollingImputed.csv")
Train = subset(polling, Year < 2012)
Test = subset(polling, Year == 2012)
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
TestPrediction = predict(mod2, newdata=Test, type="response")
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
table(TestPredictionBinary) 
mean(TestPrediction)
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
predictionMap = predictionMap[order(predictionMap$order)
]
predictionMap = predictionMap[order(predictionMap$order)]
predictionMap = predictionMap[order(predictionMap$order),]
str(predictionMap)
str(statesMap)
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) + geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black", linetype=3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black", size=3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black", alpha=0.3) + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
edges = read.csv("edges.csv")
users = read.csv("users.csv")
str(users)
str(edges)
292/59=4.95
table(users$locale, users$school)
table(users$gender, users$school)
install.packages("igraph")
library(igraph)
?graph.data.frame
table(degree(g)) or table(degree(g) >= 10)
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
summary(degree(g))
18/2+2=11
0/2+2=2
V(g)$gender
V(g)$school
V(g)$locale
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
run plot(g, vertex.label=NA)
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "gray"
plot(g, vertex.label=NA)
rglplot(g, vertex.label=NA)
 plot(g, edge.width=2, vertex.label=NA) 
edge.width
edges = read.csv("edges.csv")
users = read.csv("users.csv")
str(users)
str(edges)
292/59=4.95
table(users$locale, users$school)
table(users$gender, users$school)
install.packages("igraph")
library(igraph)
?graph.data.frame
g = graph.data.frame(edges, FALSE, users)
table(degree(g) >= 10)
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
summary(degree(g))
18/2+2=11
0/2+2=2
V(g)$gender
V(g)$school
V(g)$locale
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
run plot(g, vertex.label=NA)
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "gray"
plot(g, vertex.label=NA)
rglplot(g, vertex.label=NA)
 plot(g, edge.width=2, vertex.label=NA) 
edges = read.csv("edges.csv")
users = read.csv("users.csv")
str(users)
str(edges)
292/59=4.95
table(users$locale, users$school)
table(users$gender, users$school)
install.packages("igraph")
library(igraph)
?graph.data.frame
g = graph.data.frame(edges, FALSE, users)
table(degree(g) >= 10)
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
summary(degree(g))
18/2+2=11
0/2+2=2
V(g)$gender
V(g)$school
V(g)$locale
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
plot(g, vertex.label=NA)
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "gray"
plot(g, vertex.label=NA)
install.packages("rgl")
library(rgl)
rglplot(g, vertex.label=NA)
plot(g, edge.width=2, vertex.label=NA) 
q()
library(tm)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
corpus = VCorpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
ncol(allTweets)
install.package("wordcloud")
install.packages("wordcloud")
library(wordcloud)
Skip to main content
 edX Home Page
Course , current location 
Discussion
Progress
Syllabus
Schedule
Files
Wiki
Course   Unit 7: Visualization   Assignment 7   Visualizing Text Data Using Word Clouds
 Previous
Next 
 problem Election Forecasting Revisited 
 problem Visualizing Network Data 
 problem Visualizing Text Data Using Word Clouds 
 problem Visualizing Attributes of Parole Violators (OPTIONAL) 
 other Unit 7 Feedback 
Audit Access Expires Jul. 17, 2019
You lose all access to this course, including your progress, on Jul. 17, 2019.
Visualizing Text Data Using Word Clouds
 Bookmark this page
Visualizing Text Data Using Word CLouds
Earlier in the course, we used text analytics as a predictive tool, using word frequencies as independent variables in our models. However, sometimes our goal is to understand commonly occurring topics in text data instead of to predict the value of some dependent variable. In such cases, word clouds can be a visually appealing way to display the most frequent words in a body of text.
A word cloud arranges the most common words in some text, using size to indicate the frequency of a word. For instance, this is a word cloud for the complete works of Shakespeare, removing English stopwords:
Shakespeare word cloud
While we could generate word clouds using free generators available on the Internet, we will have more flexibility and control over the process if we do so in R. We will visualize the text of tweets about Apple, a dataset we used earlier in the course. As a reminder, this dataset (which can be downloaded from tweets.csv) has the following variables:
Tweet -- the text of the tweet
Avg -- the sentiment of the tweet, as assigned by users of Amazon Mechanical Turk. The score ranges on a scale from -2 to 2, where 2 means highly positive sentiment, -2 means highly negative sentiment, and 0 means neutral sentiment.
Problem 1.1 - Preparing the Data
1 point possible (graded)
Download the dataset "tweets.csv", and load it into a data frame called "tweets" using the read.csv() function, remembering to use stringsAsFactors=FALSE when loading the data.
Next, perform the following pre-processing tasks (like we did in Unit 5), noting that we don't stem the words in the document or remove sparse terms:
1) Create a corpus using the Tweet variable
2) Convert the corpus to lowercase
3) Remove punctuation from the corpus
4) Remove all English-language stopwords
5) Build a document-term matrix out of the corpus
6) Convert the document-term matrix to a data frame called allTweets
How many unique words are there across all the documents?
  unanswered  3780
Explanation
We can complete the pre-processing steps with the following commands:
library(tm)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
corpus = VCorpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
From the commands "frequencies", "str(allTweets)" or "ncol(allTweets)", we can read that there are 3780 unique words across all the tweets.
 Submit You have used 0 of 3 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Answers are displayed within the problem Review
Problem 1.2 - Preparing the Data
1 point possible (graded)
Although we typically stem words during the text preprocessing step, we did not do so here. What is the most compelling rationale for skipping this step when visualizing text data?
It avoids the computational burden of stemming
It will be easier to read and understand the word cloud if it includes full words instead of just the word stems correct
We would not be able to create a word cloud if we stemmed the document
unanswered
Explanation
We want to create an interpretable display of a document's contents, and our results will be easier to read if they include full words instead of just the stems.
Stemming has relatively minor computational burden, and we certainly could create a word cloud with a stemmed document.
 Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Answers are displayed within the problem Review
Problem 2.1 - Building a Word Cloud
1 point possible (graded)
Install and load the "wordcloud" package, which is needed to build word clouds.
Explanation
This can be done with:
install.packages("wordcloud")
library(wordcloud)
As we can read from ?wordcloud, we will need to provide the function with a vector of words and a vector of word frequencies. Which function can we apply to allTweets to get a vector of the words in our dataset, which we'll pass as the first argument to wordcloud()?
str
rownames
colnames correct
unanswered
Explanation
Each tweet represents a row of allTweets, and each word represents a column. We need the names of all the columns of allTweets, which is returned by colnames(allTweets). While str(allTweets) displays the names of the variables along with other information, it doesn't return a vector that we can use as the first argument to wordcloud().
 Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Answers are displayed within the problem Review
Problem 2.2 - Building a Word Cloud
1 point possible (graded)
Which function should we apply to allTweets to obtain the frequency of each word across all tweets?
colSums
rowSums
sum
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 2.3 - Building a Word Cloud
1 point possible (graded)
Use allTweets to build a word cloud. Make sure to check out the help page for wordcloud if you are not sure how to do this.
Because we are plotting a large number of words, you might get warnings that some of the words could not be fit on the page and were therefore not plotted -- this is especially likely if you are using a smaller screen. You can address these warnings by plotting the words smaller. From ?wordcloud, we can see that the "scale" parameter controls the sizes of the plotted words. By default, the sizes range from 4 for the most frequent words to 0.5 for the least frequent, as denoted by the parameter "scale=c(4, 0.5)". We could obtain a much smaller plot with, for instance, parameter "scale=c(2, 0.25)".
What is the most common word across all the tweets (it will be the largest in the outputted word cloud)? Please type the word exactly how you see it in the word cloud. The most frequent word might not be printed if you got a warning about words being cut off -- if this happened, be sure to follow the instructions in the paragraph above.
  unanswered  
Submit You have used 0 of 3 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 2.4 - Building a Word Cloud
1 point possible (graded)
In the previous subproblem, we noted that there is one word with a much higher frequency than the other words. Repeat the steps to load and pre-process the corpus, this time removing the most frequent word in addition to all elements of stopwords("english") in the call to tm_map with removeWords. For a refresher on how to remove this additional word, see the Twitter text analytics lecture.
Replace allTweets with the document-term matrix of this new corpus -- we will use this updated corpus for the remainder of the assignment.
Create a word cloud with the updated corpus. What is the most common word in this new corpus (the largest word in the outputted word cloud)? The most frequent word might not be printed if you got a warning about words being cut off -- if this happened, be sure to follow the instructions in the previous problem.
  unanswered  
Submit You have used 0 of 3 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 3 - Size and Color
So far, the word clouds we've built have not been too visually appealing -- they are crowded by having too many words displayed, and they don't take advantage of color. One important step to building visually appealing visualizations is to experiment with the parameters available, which in this case can be viewed by typing ?wordcloud in your R console. In this problem, you should look through the help page and experiment with different parameters to answer the questions.
Below are four word clouds, each of which uses different parameter settings in the call to the wordcloud() function:
Word Cloud A:
Word Cloud A
Word Cloud B:
Word Cloud B
Word Cloud C:
Word Cloud C
Word Cloud D:
Word Cloud D
We will refer to these four word clouds in the next several problems.
Problem 3.1 - Size and Color
1 point possible (graded)
Which word cloud is based only on the negative tweets (tweets with Avg value -1 or less)?
Word Cloud A
Word Cloud B
Word Cloud C
Word Cloud D
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 3.2 - Size and Color
1 point possible (graded)
Only one word cloud was created without modifying parameters min.freq or max.words. Which word cloud is this?
Word Cloud A
Word Cloud B
Word Cloud C
Word Cloud D
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 3.3 - Size and Color
1 point possible (graded)
Which word clouds were created with parameter random.order set to FALSE?
Word Cloud A
Word Cloud B
Word Cloud C
Word Cloud D
unanswered
Submit You have used 0 of 2 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 3.4 - Size and Color
1 point possible (graded)
Which word cloud was built with a non-default value for parameter rot.per?
Word Cloud A
Word Cloud B
Word Cloud C
Word Cloud D
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 3.5 - Size and Color
1 point possible (graded)
In Word Cloud C and Word Cloud D, we provided a color palette ranging from light purple to dark purple as the parameter colors (you will learn how to make such a color palette later in this assignment). For which word cloud was the parameter random.color set to TRUE?
Word Cloud C
Word Cloud D
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 4.1 - Selecting a Color Palette
1 point possible (graded)
The use of a palette of colors can often improve the overall effect of a visualization. We can easily select our own colors when plotting; for instance, we could pass c("red", "green", "blue") as the colors parameter to wordcloud(). The RColorBrewer package, which is based on the ColorBrewer project (colorbrewer.org), provides pre-selected palettes that can lead to more visually appealing images. Though these palettes are designed specifically for coloring maps, we can also use them in our word clouds and other visualizations.
Begin by installing and loading the "RColorBrewer" package. This package may have already been installed and loaded when you installed and loaded the "wordcloud" package, in which case you don't need to go through this additional installation step. If you obtain errors (for instance, "Error: lazy-load database 'P' is corrupt") after installing and loading the RColorBrewer package and running some of the commands, try closing and re-opening R.
The function brewer.pal() returns color palettes from the ColorBrewer project when provided with appropriate parameters, and the function display.brewer.all() displays the palettes we can choose from.
Which color palette would be most appropriate for use in a word cloud for which we want to use color to indicate word frequency?
Accent
Set2
YlOrRd
unanswered
Submit You have used 0 of 1 attempt Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 4.2 - Selecting a Color Palette
1 point possible (graded)
Which RColorBrewer palette name would be most appropriate to use when preparing an image for a document that must be in grayscale?
  unanswered  
Submit You have used 0 of 2 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
Problem 4.3 - Selecting a Color Palette
1 point possible (graded)
In sequential palettes, sometimes there is an undesirably large contrast between the lightest and darkest colors. You can see this effect when plotting a word cloud for allTweets with parameter colors=brewer.pal(9, "Blues"), which returns a sequential blue palette with 9 colors.
Which of the following commands addresses this issue by removing the first 4 elements of the 9-color palette of blue colors? Select all that apply.
brewer.pal(9, "Blues")[c(-5, -6, -7, -8, -9)]
brewer.pal(9, "Blues")[c(-1, -2, -3, -4)]
brewer.pal(9, "Blues")[c(1, 2, 3, 4)]
brewer.pal(9, "Blues")[c(5, 6, 7, 8, 9)]
unanswered
Submit You have used 0 of 2 attempts Some problems have options such as save, reset, hints, or show answer. These options follow the Submit button.
Show Answer
 Please remember not to ask for or post complete answers to homework questions in this discussion forum.
Discussion
Topic: Unit 7 / Unit 7, Recitation: Visualizing Text Data Using Word Clouds
Hide Discussion
Add a Post
Filter:Sort:
discussion
Question 4.3
The sentence "Which of the following commands addresses .." implies a single answer. For multiple it should be "Which of the following commands address .."
1 comments
discussion
error when using tm_map function
I am getting below error when using tm_map function: Corpus = tm_map(Corpus,tolower) Warning message: In tm_map.SimpleCorpus(Corpus, tolower) : transformation drops documents > Corpus = tm_map(Corpus,removePunctuation) Warning message: In tm_map.SimpleCorpus(Corpus, removePunctuation) : transformation drops documents Please help me!
3 comments (3 unread comments)
answered question
Problem 3.4
While I understand the meaning of the rot.per parameter and its default value, I cannot really distinguish it by merely looking at the four Word Clouds. Is there a way to answer to this question that does not rely on me counting the proportion of vertical words per each cloud? thanks.
4 comments (4 unread comments)
answered question
Cannot install wordcloud package
I tried to install wordcloud package using the install.packages command but it seems not available in 3.5.1 R version. Any ideas? Thank you!
3 comments (3 unread comments)
 Previous
Next 
© All Rights Reserved
Enter equation
 Result
edX Home Page
edX
About
edX for Business
Legal
Terms of Service & Honor Code
Privacy Policy
Accessibility Policy
Connect
Blog
Contact Us
Help Center
Like edX on Facebook
Follow edX on Twitter
Subscribe to the edX YouTube channel
Follow edX on LinkedIn
Follow edX on Google+
Subscribe to the edX subreddit
 Download the edX mobile app from the Apple App Store
 Download the edX mobile app from Google Play
© 2012–2019 edX Inc. 
EdX, Open edX, and MicroMasters are registered trademarks of edX Inc. | 
 colSums(allTweets)
q()
colSums(allTweets)
scale=c(4, 0.5)
scale=c(2, 0.25)
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets), colSums(allTweets)
scale=c(2, .25))
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(frequencies))
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets)
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2, 0.25))
negativeTweets = subset(allTweets, tweets$Avg <= -1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets))
rot.per=0.5
 c("red", "green", "blue")
install.package("RColorBrewer")
install.packages("RColorBrewer")
library(RColorBrewer)
display.brewer.all()
colors=brewer.pal(9, "Blues")
brewer.pal(9, "Blues")[-1:-4]
brewer.pal(9, "Blues")[5:9]
q()
