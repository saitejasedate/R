q()
q()
sd(c(5,8,12))
which.min(c(4,1,6))
demo()
q()
q()
stevens = read.csv("stevens.csv")
str(stevens)
library(caTools)
set.seed(3000)
spl = sample.split(stevens$reverse, SplitRatio=0.7)
spl = sample.split(stevens$Reverse, SplitRatio=0.7)
Train = subset(stevens, spl == TRUE)
Test = subset(stevens, spl == FALSE)
library(rpart)
q()
Train = subset(stevens, spl == TRUE)
Test = subset(stevens, spl == FALSE)
library(rpart)
library(rpart.plot)
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "class", minBucket = 25)
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "class", minbucket = 25)
prp(StvensTree)
prp(StevensTree)
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
library(ROCR)
install.package(ROCR)
install.packages(ROCR)
install.package("ROCR")
install.packages("ROCR")
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr","fpr")
plot(perf)
install.packages("randomForest")
library(randomForest)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, nodesize = 25, ntree = 200)
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, nodesize = 25, ntree = 200)
PredictForest = predict(STevensForest, newdata = Test)
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
install.packages("caret")
library(caret)
install.packages("e1071")
library(e1071)
q()
gerber =  read.csv("gerber.csv")
str(gerber)
table(gerber$voting)
108696/108696+235388
108696+235388
108696/344084
tapply(gerber$voting, gerber$civicduty, mean)
tapply(gerber$voting, gerber$hawthorne, mean)
tapply(gerber$voting, gerber$self, mean)
tapply(gerber$voting, gerber$neighbors, mean)
q()
q()
gerber = read.csv("gerber.csv")
str(gerber)
table(gerber$voting)
108696/(108696+235388)
tapply(gerber$voting, gerber$civicduty, mean)
tapply(gerber$voting, gerber$hawthorne, mean)
tapply(gerber$voting, gerber$self, mean)
tapply(gerber$voting, gerber$neighbors, mean)
model1 = glm(voting ~ hawthorne + civicduty + neighbors + self, data = gerber, family = "binomial")
summary(model1)
predictLog = predict(model1, type="response")
table(gerber$voting, predictLog > 0.3)
(134513+51966)/(134516+100875+56730+51966)
table(gerber$voting, predictLog > 0.5)
(235388)/(235388+108696)
library(ROCR)
ROCRpred = prediction(predictLog, gerber$voting)
as.numeric(performance(ROCRpred, "auc")@y.values)
library(rpart)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data = gerber)
library(rpart.plot)
prp(CARTmodel)
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data = gerber, cp = 0.0)
prp(CARTmodel2)
CARTmodel3 = rpart(voting ~ civicduty + hawthorne + self + neighbors + sex, data = gerber, cp = 0.0)
prp(CARTmodel3)
CARTmodel4 = rpart(voting ~ control, data = gerber, cp = 0.0)
prp(CARTmodel4, digits = 6)
CARTmodel5 = rpart(voting ~ control + sex, data = gerber, cp = 0.0)
prp(CARTmodel5, digits = 6)
abs(0.34-0.296638)
model2 = glm(voting ~ sex + control, data = gerber, family = "binomial")
summary(model2)
Possibilites = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(model2, newdata = Possibilites, type = "response")
abs(0.290456-0.2908065)
model2 = glm(voting ~ sex + control + sex:control, data = gerber, family = "binomial")
summary(model2)
predict(model2, newdata = Possibilites, type = "response")
letter = read.csv("letters_ABPR.csv")
letter$isB = as.factor(letter$letter == "B")
library(caTools)
set.seed(1000)
spl = sample.split(letter$isB, SplitRatio=0.5)
Train = subset(letter, spl == TRUE)
Test = subset(letter, spl == FALSE)
table(Test$isB)
1175/(1175+383)
library(rpart)
CARTmodel1 = rpart(isB ~ . -letter, data = Train, method = "class")
predictions = predict(CARTmodel1, newdata = Test, type = "class")
table(Test$isB, predictions)
(1134+327)/nrow(Test)
set.seed(1000)
library(randomForest)
RFmodel = randomForest(isB ~ . -letter, data = Train)
predictions = predict(RFmodel, newdata = Test)
table(Test$isB, predictions)
(1161+371)/(1161+14+12+371)
letter$letter = as.factor(letter$letter)
set.seed(2000)
spl = sample.split(letter$letter, SplitRatio = 0.5)
Train2 = subset(letter, spl == TRUE)
Test2 = subset(letter, spl == FALSE)
table(Train2$letter)
table(Test2$letter)
401/nrow(Test)
CARTmodel2 = rpart(letter ~ . -isB, data = Train2, method = "class")
predictLetter = predict(CARTmodel2, newdata = Test2, type = "class")
table(Test2$letter, predictLetter)
(348+318+363+340)/nrow(Test2)
set.seed(1000)
RFmodel2 = randomForest(letter ~ . -isB, data = Train2)
predictLetter = predict(RFmodel2, newdata = Test2)
table(Test2$letter, predictLetter)
(391+380+394+362)/nrow(Test2)
census = read.csv("census.csv")
str(census)
library(caTools)
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
Train = subset(census, spl == TRUE)
Test = subset(census, spl == FALSE)
model1 = glm(over50k ~ ., data = Train, family = "binomial")
summary(model1)
predictModel1 = predict(model1, newdata = Test, type = "response")
table(Test$over50k, predictModel1 >= 0.5)
(9051+1888)/nrow(Test)
table(Train$over50k)
table(Test$over50k)
(9713)/(9713+3078)
library(ROCR)
ROCRpred = prediction(predictModel1, Test$over50k)
as.numeric(performance(ROCRpred, "auc")@y.values)
library(rpart)
CARTmodel1 = rpart(over50k ~ ., data = Train, method = "class")
library(rpart.plot)
prp(CARTmodel1)
predictCART = predict(CARTmodel1, newdata = Test, type = "class")
table(Test$over50k, predictCART)
(9243+1596)/(9243+470+1482+1596)
predictTest = predict(CARTmodel1, newdata = Test)
predictTest = predictTest[,2]
ROCRpred2 = prediction(predictTest, Test$over50k)
as.numeric(performance(ROCRpred2, "auc")@y.values)
set.seed(1)
trainSmall = Train[sample(nrow(Train),2000),]
set.seed(1)
library(randomForest)
RFmodel1 = randomForest(over50k ~ ., data = trainSmall)
predictTest = predict(RFmodel1, newdata = Test)
table(Test$over50k, predictTest)
(8843+2049)/nrow(Test)
vu = varUsed(RFmodel1, count = TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(RFmodel1$forest$xlevels[vusorted$ix]))
install.packages()
varImpPlot(RFmodel1)
set.seed(2)
library(caret)
fitControl = trainControl(method = "cv", number = 10)
cartGrid = expand.grid(.cp = seq(0.002,0.1,0.002))
train(over50k ~ ., data = Train, method = "rpart", trControl = fitControl, tuneGrid = cartGrid)
model = rpart(over50k ~ .,data = Train, method = "class", cp = 0.002)
predictTest = predict(model, newdata = Test, type = "class")
table(Test$over50k, predictTest)
(9178+1838)/(9178+535+1240+1838)
prp(model)
q()
