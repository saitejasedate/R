q()
q()
sd(c(5,8,12))
which.min(c(4,1,6))
demo()
q()
q()
emails = read.csv("emails.csv", stringsAsFactors = FALSE)
str(emails)
table(emails$spam)
emails$text[1]
emails$text[50]
max(nchar(emails$text))
which.min(nchar(emails$text))
library(tm)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
which.max(colSums(emailsSparse))
emailsSparse$spam = emails$spam
sort(colSums(subset(emailsSparse, spam == 0)))
sort(colSums(subset(emailsSparse, spam == 1)))
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
library(caTools)
spl = sample.split(emailsSparse, SplitRatio = 0.7)
train = subset(emailsSparse, spl == TRUE)
test = subset(emailsSparse, spl == FALSE)
spamLog = glm(spam ~ ., data = train, family = "binomial")
library(rpart)
spamCART = rpart(spam ~ ., data = train, method = "class")
library(randomForest)
spamRF = randomForest(spam ~ ., data = train)
predTrainlog = predict(spamLog, type = "response")
predTrainCART = predict(spamCART)[,2]
predTrainRF = predict(spamRF, type = "prob")[,2]
table(predTrainlog < 0.00001)
table(predTrainlog > 0.99999)
table(predTrainlog >= 0.00001 & predTrainlog <= 0.99999)
summary(spamLog)
library(rpart.plot)
prp(spamCART)
table(train$spam, predTrainlog>0.5)
(2978+917)/nrow(train)
library(ROCR)
predictionTrainLog = prediction(predTrainlog, train$spam)
as.numeric(performance(predictionTrainLog, "auc")@y.values)
table(train$spam, predTrainCART > 0.5)
(2900+894)/nrow(train)
predictionTrainCART = prediction(predTrainCART, train$spam)
as.numeric(performance(predictionTrainCART, "auc")@y.values)
table(train$spam, predTrainRF > 0.5)
(3002+916)/nrow(train)
predictionTrainRF = prediction(predTrainRF, train$spam)
as.numeric(performance(predictionTrainRF, "auc")@y.values)
predTestlog = predict(spamLog, newdata = test, type = "response")
predTestCART = predict(spamCART, newdata = test)[,2]
predTestRF = predict(spamRF, newdata = test, type = "prob")[,2]
table(test$spam, predTestlog > 0.5)
(1245+376)/nrow(test)
predictionTestlog = prediction(predTestlog, test$spam)
as.numeric(performance(predictionTestlog, "auc")@y.values)
table(test$spam, predTestCART > 0.5)
(1243+383)/nrow(test)
predictionTestCART = prediction(predTestCART, test$spam)
as.numeric(performance(predictionTestCART, "auc")@y.values)
table(test$spam, predTestRF > 0.5)
(1303+391)/nrow(test)
predictionTestRF = prediction(predTestRF, test$spam)
as.numeric(performance(predictionTestRF, "auc")@y.values)
emails = read.csv("emails.csv", stringsAsFactors = FALSE)
str(emails)
table(emails$spam)
emails$text[1]
emails$text[50]
max(nchar(emails$text))
which.min(nchar(emails$text))
library(tm)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
which.max(colSums(emailsSparse))
emailsSparse$spam = emails$spam
sort(colSums(subset(emailsSparse, spam == 0)))
sort(colSums(subset(emailsSparse, spam == 1)))
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
library(caTools)
spl = sample.split(emailsSparse, SplitRatio = 0.7)
train = subset(emailsSparse, spl == TRUE)
test = subset(emailsSparse, spl == FALSE)
spamLog = glm(spam ~ ., data = train, family = "binomial")
library(rpart)
spamCART = rpart(spam ~ ., data = train, method = "class")
library(randomForest)
spamRF = randomForest(spam ~ ., data = train)
predTrainlog = predict(spamLog, type = "response")
predTrainCART = predict(spamCART)[,2]
predTrainRF = predict(spamRF, type = "prob")[,2]
table(predTrainlog < 0.00001)
table(predTrainlog > 0.99999)
table(predTrainlog >= 0.00001 & predTrainlog <= 0.99999)
summary(spamLog)
library(rpart.plot)
prp(spamCART)
table(train$spam, predTrainlog>0.5)
(2978+917)/nrow(train)
library(ROCR)
predictionTrainLog = prediction(predTrainlog, train$spam)
as.numeric(performance(predictionTrainLog, "auc")@y.values)
table(train$spam, predTrainCART > 0.5)
(2900+894)/nrow(train)
predictionTrainCART = prediction(predTrainCART, train$spam)
as.numeric(performance(predictionTrainCART, "auc")@y.values)
table(train$spam, predTrainRF > 0.5)
(3002+916)/nrow(train)
predictionTrainRF = prediction(predTrainRF, train$spam)
as.numeric(performance(predictionTrainRF, "auc")@y.values)
predTestlog = predict(spamLog, newdata = test, type = "response")
predTestCART = predict(spamCART, newdata = test)[,2]
predTestRF = predict(spamRF, newdata = test, type = "prob")[,2]
table(test$spam, predTestlog > 0.5)
(1245+376)/nrow(test)
predictionTestlog = prediction(predTestlog, test$spam)
as.numeric(performance(predictionTestlog, "auc")@y.values)
table(test$spam, predTestCART > 0.5)
(1243+383)/nrow(test)
predictionTestCART = prediction(predTestCART, test$spam)
as.numeric(performance(predictionTestCART, "auc")@y.values)
table(test$spam, predTestRF > 0.5)
(1303+391)/nrow(test)
predictionTestRF = prediction(predTestRF, test$spam)
as.numeric(performance(predictionTestRF, "auc")@y.values)
wiki = read.csv("wiki.csv", stringsAsFactors = FALSE)
wiki$Vandal = as.factor(wiki$Vandal)
table(wiki$Vandal)
library(tm)
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
sparseAdded = removeSparseTerms(dtmAdded, 0.997)
sparseAdded
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corpusRemoved = tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved = tm_map(corpusRemoved, stemDocument)
dtmReversed = DocumentTermMatrix(corpusRemoved)
sparseRemoved = removeSparseTerms(dtmReversed, 0.997)
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
ncol(wordsRemoved)
wikiWords = cbind(wordsAdded, wordsRemoved)
wikiWords$Vandal = wiki$Vandal
library(caTools)
set.seed(123)
spl = sample.split(wikiWords$Vandal, SplitRatio = 0.7)
wikiTrain = subset(wikiWords, spl == TRUE)
wikiTest = subset(wikiWords, spl == FALSE)
table(wikiTest$Vandal)
618/(618+545)
library(rpart)
CARTmodel1 = rpart(Vandal ~ ., data = wikiTrain, method = "class")
predmodel1 = predict(CARTmodel1, newdata = wikiTest, type = "class")
table(wikiTest$Vandal, predmodel1)
(614+19)/nrow(wikiTest)
library(rpart.plot)
prp(CARTmodel1)
wikiWords2 = wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added, fixed = TRUE),1,0)
table(wikiWords2$HTTP)
wikiTrain2 = subset(wikiWords2, spl == TRUE)
wikiTest2 = subset(wikiWords2, spl == FALSE)
CARTmodel2 = rpart(Vandal ~ ., data = wikiTrain2, method = "class")
predmodel2 = predict(CARTmodel2, newdata = wikiTest2, type = "class")
table(wikiTest2$Vandal, predmodel2)
(605+13)/(nrow(wikiTest2))
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmReversed))
mean(wikiWords2$NumWordsAdded)
wikiTrain3 = subset(wikiTrain2, spl == TRUE)
wikiTest3 = subset(wikiTest2, spl == FALSE)
CARTmodel3 = rpart(Vandal ~ ., data = wikiTrain3, method = "class")
predmodel3 = predict(CARTmodel3, newdata = wikiTest3, type = "class")
table(wikiTest3$Vandal, predmodel3)
(181+15)/nrow(wikiTest3)
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
wikiTrain4 = subset(wikiWords3, spl == TRUE)
wikiTest4 = subset(wikiWords3, spl == FALSE)
CARTmodel4 = rpart(Vandal ~ ., data = wikiTrain4, method = "class")
predmodel4 = predict(CARTmodel4, newdata = wikiTest4, type = "class")
table(wikiTest4$Vandal, predmodel4)
(595+241)/nrow(wikiTest4)
prp(CARTmodel4)
trials = read.csv("clinical_trial.csv", stringsAsFactors = FALSE)
str(trials)
max(nchar(trials$abstract))
sum(nchar(trials$abstract) == 0)
which.min(nchar(trials$title))
trials$title[1258]
library(tm)
corpusTitle = Corpus(VectorSource(trials$title))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusTitle = tm_map(corpusTitle, tolower)
corpusAbstract = tm_map(corpusAbstract, tolower)
corpusTitle = tm_map(corpusTitle, removePunctuation)
corpusAbstract = tm_map(corpusAbstract, removePunctuation)
corpusTitle = tm_map(corpusTitle, removeWords, stopwords("english"))
corpusAbstract = tm_map(corpusAbstract, removeWords, stopwords("english"))
corpusTitle = tm_map(corpusTitle, stemDocument)
corpusAbstract = tm_map(corpusAbstract, stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
dtmTitle = removeSparseTerms(dtmTitle, 0.95)
dtmAbstract = removeSparseTerms(dtmAbstract, 0.95)
dtmTitle = as.data.frame(as.matrix(dtmTitle))
dtmAbstract = as.data.frame(as.matrix(dtmAbstract))
str(dtmTitle)
str(dtmAbstract)
which.max(colSums(dtmAbstract))
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtm = cbind(dtmTitle, dtmAbstract)
dtm$trial = trials$trial
str(dtm)
set.seed(144)
library(caTools)
spl = sample.split(dtm$trial, 0.7)
train = subset(dtm, spl == TRUE)
test = subset(dtm, spl == FALSE)
table(train$trial)
730/(730+572)
library(rpart)
trialCART = rpart(trial ~., data = train, method = "class")
library(rpart.plot)
prp(trialCART)
predTrain = predict(trialCART)[,2]
summary(predTrain)
table(train$trial, predTrain>=0.5)
(631+441)/nrow(train)
441/(441+131)
631/(631+99)
predTest = predict(trialCART, newdata = test, type = "class")
table(test$trial, predTest)
(261+162)/nrow(test)
library(ROCR)
predTest = predict(trialCART, newdata = test)[,2]
pred = prediction(predTest, test$trial)
as.numeric(performance(pred, "auc")@y.values)
q()
